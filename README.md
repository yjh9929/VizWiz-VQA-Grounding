# VizWiz-VQA-Grounding
2025 1st place (will)  
 This project was developed for the [VizWiz-VQA-Grounding Challenge](https://vizwiz.org/tasks-and-datasets/visual-qa/) 2025. The goal is to return grounded visual evidence for answers to visual questions posed by people with visual impairments. 


## ğŸ¶Task Objective
Given an image-question pair, the task is to predict the region in the image that supports the most common answer. This is known as **answer grounding**, and predictions are evaluated based on **mean Intersection over Union (IoU)** with human-annotated binary masks.


## ğŸ“‚Project Structure
```project/
â”œâ”€â”€ README.md
â”œâ”€â”€ models/ â”‚
    â”œâ”€â”€ init.py â”‚
    â”œâ”€â”€ image_encoder.py â”‚
    â”œâ”€â”€ text_encoder.py # me â”‚
    â”œâ”€â”€ concat.py # me â”‚
    â”œâ”€â”€ mask_decoder.py # unet â”‚
    â””â”€â”€ model.py # me
â”œâ”€â”€ data/ â”‚
    â”œâ”€â”€ binary_masks_png/ â”‚
    â”‚ â”œâ”€â”€ train/ â”‚
    â”‚ â””â”€â”€ val/ â”‚
â”œâ”€â”€ test/ â”‚
â”œâ”€â”€ train/ â”‚
â”œâ”€â”€ val/ â”‚
    â”œâ”€â”€ test_grounding.json â”‚
    â”œâ”€â”€ train_grounding.json â”‚
    â””â”€â”€ val_grounding.json
â”œâ”€â”€ train.py
â”œâ”€â”€ dataset.py
â”œâ”€â”€ utils.py
â”œâ”€â”€ visualize_predictions.py
â”œâ”€â”€ IoU.py
â”œâ”€â”€ metrics.py
â””â”€â”€ config.yml
```
## âš™ï¸ Installation


## ğŸš€ Running the Code

## ğŸ§  Model Design

## ğŸ“Š Evaluation

## ğŸ”— References

## ğŸ“ License

